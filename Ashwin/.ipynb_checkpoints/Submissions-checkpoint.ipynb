{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "\n",
    "#visualization\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CRASH DATE', 'CRASH TIME', 'BOROUGH', 'ZIP CODE', 'LATITUDE',\n",
      "       'LONGITUDE', 'LOCATION', 'ON STREET NAME', 'CROSS STREET NAME',\n",
      "       'OFF STREET NAME', 'NUMBER OF PERSONS INJURED',\n",
      "       'NUMBER OF PERSONS KILLED', 'NUMBER OF PEDESTRIANS INJURED',\n",
      "       'NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST INJURED',\n",
      "       'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST INJURED',\n",
      "       'NUMBER OF MOTORIST KILLED', 'CONTRIBUTING FACTOR VEHICLE 1',\n",
      "       'CONTRIBUTING FACTOR VEHICLE 2', 'CONTRIBUTING FACTOR VEHICLE 3',\n",
      "       'CONTRIBUTING FACTOR VEHICLE 4', 'CONTRIBUTING FACTOR VEHICLE 5',\n",
      "       'COLLISION_ID', 'VEHICLE TYPE CODE 1', 'VEHICLE TYPE CODE 2',\n",
      "       'VEHICLE TYPE CODE 3', 'VEHICLE TYPE CODE 4', 'VEHICLE TYPE CODE 5',\n",
      "       'Unnamed: 29', 'Unnamed: 30', 'Unnamed: 31', 'NUMTIME'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"MVC.csv\")\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['BOROUGH','NUMTIME','LONGITUDE','LATITUDE','CONTRIBUTING FACTOR VEHICLE 1','NUMBER OF PERSONS KILLED','NUMBER OF PERSONS INJURED','NUMBER OF PEDESTRIANS KILLED','NUMBER OF PEDESTRIANS INJURED']]\n",
    "data['PERSONS_AFFECTED'] = data['NUMBER OF PERSONS KILLED'] + data['NUMBER OF PERSONS INJURED']\n",
    "data['PEDESTRIANS_AFFECTED'] = data['NUMBER OF PEDESTRIANS KILLED'] + data['NUMBER OF PEDESTRIANS INJURED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough_dummy = data.BOROUGH.str.get_dummies()\n",
    "data = pd.concat([data,borough_dummy],axis=1)\n",
    "\n",
    "data = data.dropna()\n",
    "data = data[data.LONGITUDE !=0]\n",
    "\n",
    "data['PERSONS_TF']=0\n",
    "data.loc[data['PERSONS_AFFECTED'] > 0, 'PERSONS_TF']= 1\n",
    "data.loc[data['PERSONS_AFFECTED'] == 0, 'PERSONS_TF']= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = data[\"CONTRIBUTING FACTOR VEHICLE 1\"].value_counts(ascending=True)\n",
    "remove = value_counts[value_counts <= 20].index\n",
    "data = data[~data['CONTRIBUTING FACTOR VEHICLE 1'].isin(remove)]\n",
    "\n",
    "data['CONTRIBUTING FACTOR VEHICLE 1'] = data['CONTRIBUTING FACTOR VEHICLE 1'].replace(['Driver Inattention/Distraction','Following Too Closely','Failure to Yield Right-of-Way','Backing Unsafely','Passing Too Closely','Unsafe Lane Changing','Passing or Lane Usage Improper','Turning Improperly','Traffic Control Disregarded','Driver Inexperience','Reaction to Uninvolved Vehicle','Unsafe Speed','Fatigued/Drowsy','Alcohol Involvement','Lost Consciousness','Aggressive Driving/Road Rage','Fell Asleep','Illnes','Drugs (illegal)','Drugs (Illegal)','Texting','Outside Car Distraction','Passenger Distraction','Prescription Medication','Failure to Keep Right','Illness','Other Electronic Device','Cell Phone (hand-Held)','Cell Phone (hands-free)','Eating or Drinking','Pedestrian/Bicyclist/Other Pedestrian Error/Confusion','Physical Disability','Reaction to Other Uninvolved Vehicle','Using On Board Navigation Device','Tinted Windows','Vehicle Vandalism','Cell Phone (hand-held)'],'Human')\n",
    "data['CONTRIBUTING FACTOR VEHICLE 1'] = data['CONTRIBUTING FACTOR VEHICLE 1'].replace(['Other Vehicular','Oversized Vehicle','Brakes Defective','Steering Failure','Tire Failure/Inadequate','Driverless/Runaway Vehicle','Accelerator Defective','Other Lighting Defects','Tow Hitch Defective','Headlights Defective','Windshield Inadequate'],'Vehicular')\n",
    "data['CONTRIBUTING FACTOR VEHICLE 1'] = data['CONTRIBUTING FACTOR VEHICLE 1'].replace(['Pavement Slippery','View Obstructed/Limited','Glare','Obstruction/Debris','Pavement Defective','Animals Action','Lane Marking Improper/Inadequate','Traffic Control Device Improper/Non-Working','Shoulders Defective/Improper'],'Environmental')\n",
    "data['CONTRIBUTING FACTOR VEHICLE 1'] = data['CONTRIBUTING FACTOR VEHICLE 1'].replace(['80'],'Unspecified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_dummy = data['CONTRIBUTING FACTOR VEHICLE 1'].str.get_dummies()\n",
    "data = pd.concat([data,factor_dummy],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 529959, 1: 529959})\n"
     ]
    }
   ],
   "source": [
    "pred = list(zip(data['NUMTIME'],data['MANHATTAN'],data['QUEENS'],data['BRONX'],data['STATEN ISLAND'],data['BROOKLYN'],data['Human'],data['Environmental'],data['Vehicular'],data['Unspecified']))\n",
    "resp = data['PERSONS_TF']\n",
    "sm = SMOTE(random_state=42)\n",
    "x_res,y_res = sm.fit_resample(pred,resp)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  5.5min\n",
      "/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed: 36.1min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 50.3min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.809755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.809755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>0.809755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.809755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.809755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.809755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.809755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>0.809755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.809755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.809755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_criterion param_max_depth param_min_samples_leaf  mean_test_score\n",
       "0            gini               1                     10         0.809755\n",
       "1         entropy               4                     20         0.809755\n",
       "2         entropy               3                     60         0.809755\n",
       "3         entropy               3                     50         0.809755\n",
       "4         entropy               3                     30         0.809755\n",
       "5         entropy               3                     20         0.809755\n",
       "6         entropy               3                     10         0.809755\n",
       "7         entropy               2                     60         0.809755\n",
       "8         entropy               2                     50         0.809755\n",
       "9         entropy               2                     30         0.809755"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feat = pred\n",
    "y = resp\n",
    "X_feat_train,X_feat_test, y_feat_train,y_feat_test = train_test_split(X_feat,y,test_size=0.2)\n",
    "\n",
    "dtc = RandomForestClassifier()\n",
    "grid={'max_depth':[1,2,3,4,5,10,20,30],\n",
    "        'criterion':['gini','entropy'],\n",
    "        'min_samples_leaf':[10,20,30,50,60]}\n",
    "\n",
    "gs = GridSearchCV(dtc,grid,cv=3,verbose=True,return_train_score=False,n_jobs=-1)\n",
    "gs.fit(X_feat,y)\n",
    "\n",
    "scores = pd.DataFrame(gs.cv_results_).filter(regex='param_+|mean_test_score'\n",
    "                                            ).sort_values('mean_test_score',\n",
    "                                                          ascending=False).reset_index().drop(['index'],axis=1)\n",
    "scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89    105961\n",
      "           1       0.00      0.00      0.00     24933\n",
      "\n",
      "    accuracy                           0.81    130894\n",
      "   macro avg       0.40      0.50      0.45    130894\n",
      "weighted avg       0.66      0.81      0.72    130894\n",
      "\n",
      "Null accuracy on the test set:  0.19048237505156845\n",
      "Sensitivity/Recall (TPR):  0.8095176249484316\n",
      "Precision (PPV):  0.8095176249484316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[105961,      0],\n",
       "       [ 24933,      0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_feat, y, test_size=0.2)\n",
    "\n",
    "\n",
    "t = RandomForestClassifier(criterion='entropy',max_depth=4,min_samples_leaf=20)\n",
    "\n",
    "t.fit(X_train,y_train)\n",
    "y_test_pred = t.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Classification Report:\\n\", metrics.classification_report(y_test,y_test_pred))\n",
    "print(\"Null accuracy on the test set: \",y_test.mean())\n",
    "print(\"Sensitivity/Recall (TPR): \",metrics.recall_score(y_test,y_test_pred,average='micro'))\n",
    "print(\"Precision (PPV): \", metrics.precision_score(y_test,y_test_pred,average='micro'))\n",
    "cm = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feat = data[['LATITUDE',\"LONGITUDE\",'NUMTIME','BRONX','BROOKLYN','MANHATTAN','QUEENS','STATEN ISLAND','Environmental','Human','Unspecified','Vehicular']]\n",
    "y = resp\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_feat, y, test_size=0.2)\n",
    "\n",
    "dtc = MLPClassifier(verbose=True)\n",
    "grid = {'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        'max_iter': [100,200,500,1000,2000]}\n",
    "\n",
    "gs = GridSearchCV(dtc,grid,cv=3,verbose=True,return_train_score=False)\n",
    "gs.fit(X_feat,y)\n",
    "\n",
    "scores = pd.DataFrame(gs.cv_results_).filter(regex='param_+|mean_test_score'\n",
    "                                            ).sort_values('mean_test_score',\n",
    "                                                          ascending=False).reset_index().drop(['index'],axis=1)\n",
    "scores.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
